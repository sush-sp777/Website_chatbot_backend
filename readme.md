# ğŸ§  Website Chatbot (RAG using Mistral + FastAPI + LangChain)

This project is an intelligent chatbot built using **FastAPI** and **LangChain**, powered by **Mistral via Ollama**.  
It performs Retrieval-Augmented Generation (RAG) by scraping and embedding data from the website using **FAISS**, and serves context-specific responses via a REST API.

---

## ğŸ”§ Requirements

- Python 3.10+
- Ollama (for running Mistral locally)

Install Python dependencies:

```bash
pip install -r requirements.txt

ğŸ§© Steps to Run
1ï¸âƒ£ Scrape website content
Extract data using:

python scrape.py

2ï¸âƒ£ Clean the scraped text
Format and filter the content:

python clean.py

3ï¸âƒ£ Install Ollama
Download and install Ollama from:
ğŸ‘‰ https://ollama.com/download

4ï¸âƒ£ Pull the Mistral model
Once Ollama is installed, open your terminal and run:

ollama pull mistral

Wait until you see a success message confirming the model is ready.

5ï¸âƒ£ Start the FastAPI server

ğŸš€ How to Use (via Swagger UI)
Once the server is running, open your browser and go to:
ğŸ‘‰ http://127.0.0.1:8000/docs

Under the /chat POST endpoint, click "Try it out"

Click Execute to see the chatbot's response powered by Mistral + LangChain

ğŸ“ Project Structure (optional to include)

chatbot/
â”œâ”€â”€ main.py           # FastAPI app
â”œâ”€â”€ scrape.py         # Web scraping logic
â”œâ”€â”€ clean.py          # Text cleaning and formatting
â”œâ”€â”€ requirements.txt  # Python dependencies
